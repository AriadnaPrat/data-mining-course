{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdBEZxxsD_pL"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import nltk\n",
        "import gzip\n",
        "import random\n",
        "import statistics\n",
        "import secrets\n",
        "import re\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pORv6lVD_pM"
      },
      "source": [
        "# 0. Dataset and how to iterate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlcCs39sD_pN"
      },
      "outputs": [],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "INPUT_FILE = \"movie_lines.tsv.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AexwthMuD_pN"
      },
      "outputs": [],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "POS_NOUN = 'NN'\n",
        "POS_VERB = 'VB'\n",
        "POS_ADJECTIVE = 'JJ'\n",
        "\n",
        "# Producer in Python that reads a file by words that are nouns\n",
        "def read_by_parts_of_speech(filename, parts_of_speech, max_words=-1, report_every=-1):\n",
        "\n",
        "    # Open the input file\n",
        "    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
        "\n",
        "        # Initialize counter of words to stop at max_words\n",
        "        counter = 0\n",
        "\n",
        "        # Iterate through lines in the file\n",
        "        for line in file:\n",
        "\n",
        "            elements = line.split(\"\\t\")\n",
        "\n",
        "            text = \"\"\n",
        "            if len(elements) >= 5:\n",
        "                text = elements[4].strip()\n",
        "\n",
        "            if counter > max_words and max_words != -1:\n",
        "                break\n",
        "\n",
        "            for sentence in nltk.sent_tokenize(text):\n",
        "\n",
        "                tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "                for word in [part[0] for part in tagged if part[1] in parts_of_speech]:\n",
        "\n",
        "                    counter += 1\n",
        "\n",
        "                    # Report\n",
        "                    if (report_every != -1) and (counter % report_every == 0):\n",
        "                        if max_words == -1:\n",
        "                            print(\"- Read %d words so far\" % (counter))\n",
        "                        else:\n",
        "                            print(\"- Read %d/%d words so far\" % (counter, max_words))\n",
        "\n",
        "                    # Produce the word in lowercase\n",
        "                    yield word.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcdkP4AtIyM8",
        "outputId": "fc55a225-8c28-46c5-b76b-724dac584415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xhabcxvD_pO",
        "outputId": "c49d8970-cbf3-4039-fc40-2cc1a81e1c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current noun 'greasy'\n",
            "Current noun 'shoot'\n",
            "Current noun 'same'\n",
            "Current noun 'chief'\n",
            "Current noun 'important'\n",
            "Current noun 'few'\n",
            "Current noun 'own'\n",
            "Current noun 'incept'\n",
            "Current noun 'rude'\n",
            "Current noun 'hungry'\n",
            "- Read 10000/30000 words so far\n",
            "Current noun 'deep'\n",
            "Current noun 'interested'\n",
            "Current noun 'old'\n",
            "Current noun 'welcome'\n",
            "Current noun 'american'\n",
            "Current noun 'hard'\n",
            "Current noun 'goddamn'\n",
            "Current noun 'proper'\n",
            "Current noun 'mexican'\n",
            "Current noun 'astonishing'\n",
            "Current noun 'fuckin'\n",
            "Current noun 'first'\n",
            "Current noun 'exact'\n",
            "- Read 20000/30000 words so far\n",
            "Current noun 'good'\n",
            "Current noun 'noble'\n",
            "Current noun 'sure'\n",
            "Current noun 'educational'\n",
            "Current noun 'terrible'\n",
            "Current noun 'stupid'\n",
            "Current noun 'warm'\n",
            "Current noun 'wrong'\n",
            "Current noun 'new'\n",
            "Current noun 'nice'\n",
            "Current noun 'erudite'\n",
            "Current noun 'well-'\n",
            "Current noun 'good'\n",
            "- Read 30000/30000 words so far\n"
          ]
        }
      ],
      "source": [
        "for word in read_by_parts_of_speech(INPUT_FILE, [POS_ADJECTIVE], max_words=30000, report_every=10000):\n",
        "    # Prints 1/1000 of words\n",
        "    if random.random() < 0.001:\n",
        "        print(\"Current noun '%s'\" % (word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PAJNGpwD_pO"
      },
      "source": [
        "# 1. Determine approximately the top-10 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v4ZDwmjD_pP"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"add_reservoir\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_to_reservoir(reservoir, item, max_reservoir_size):\n",
        "    if len(reservoir) < max_reservoir_size:\n",
        "        reservoir.append(item)\n",
        "    else:\n",
        "        if random.random() < max_reservoir_size / (len(reservoir) + 1):\n",
        "            evict_index = random.randint(0, len(reservoir) - 1)\n",
        "            reservoir[evict_index] = item"
      ],
      "metadata": {
        "id": "hMm0ITVXEYgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaDoHq4jD_pP"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"reservoir_sampling\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reservoir_sampling(filename, POS, reservoir_size, max_words=-1, report_every=-1):\n",
        "    reservoir = []\n",
        "    words_read = 0\n",
        "\n",
        "    for word in read_by_parts_of_speech(filename, POS, max_words=max_words, report_every=report_every):\n",
        "        add_to_reservoir(reservoir, word, reservoir_size)\n",
        "        words_read += 1\n",
        "\n",
        "    return (words_read, reservoir)"
      ],
      "metadata": {
        "id": "vsK6U1O8Kk0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEmmfiMcD_pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa922ea-f847-443f-a1fd-1193d6b2999b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Number of items seen    : 30001\n",
            "Number of items sampled : 1500\n"
          ]
        }
      ],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "reservoir_size = 1500\n",
        "(items_seen, reservoir) = reservoir_sampling(INPUT_FILE, [POS_ADJECTIVE], reservoir_size, max_words=30000, report_every=10000)\n",
        "\n",
        "print(\"Number of items seen    : %d\" % items_seen)\n",
        "print(\"Number of items sampled : %d\" % len(reservoir) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBFzXtFhD_pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc63ef45-7ce4-4935-880e-4f3b83541d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 good\n",
            "33 right\n",
            "32 other\n",
            "32 little\n",
            "32 dead\n",
            "27 big\n",
            "25 sure\n",
            "22 real\n",
            "21 old\n",
            "20 last\n",
            "18 wrong\n",
            "18 sorry\n",
            "18 much\n",
            "15 whole\n",
            "14 next\n",
            "14 great\n",
            "14 first\n",
            "14 few\n",
            "13 ready\n",
            "12 long\n"
          ]
        }
      ],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "freq = {}\n",
        "for item in reservoir:\n",
        "    freq[item] = reservoir.count(item)\n",
        "\n",
        "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:20]\n",
        "for absolute_frequency, word in most_frequent_items:\n",
        "    print(\"%d %s\" % (absolute_frequency, word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q-Ixf6lD_pP"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code to print the top items and their relative frequencies</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute relative frequencies\n",
        "total_items_in_reservoir = len(reservoir)\n",
        "print(\"Top 20 most frequent items and their relative frequencies:\")\n",
        "\n",
        "for absolute_frequency, word in most_frequent_items:\n",
        "    relative_frequency = (absolute_frequency / total_items_in_reservoir) * 100\n",
        "    print(f\"{absolute_frequency} ({relative_frequency:.2f}%) {word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c92e5JGYAty3",
        "outputId": "449c07f4-2aaf-4c87-a35e-7de2d2f9788e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 most frequent items and their relative frequencies:\n",
            "54 (3.60%) good\n",
            "33 (2.20%) right\n",
            "32 (2.13%) other\n",
            "32 (2.13%) little\n",
            "32 (2.13%) dead\n",
            "27 (1.80%) big\n",
            "25 (1.67%) sure\n",
            "22 (1.47%) real\n",
            "21 (1.40%) old\n",
            "20 (1.33%) last\n",
            "18 (1.20%) wrong\n",
            "18 (1.20%) sorry\n",
            "18 (1.20%) much\n",
            "15 (1.00%) whole\n",
            "14 (0.93%) next\n",
            "14 (0.93%) great\n",
            "14 (0.93%) first\n",
            "14 (0.93%) few\n",
            "13 (0.87%) ready\n",
            "12 (0.80%) long\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXRBmUOGD_pP"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Increase the max limit of words so that one pass takes about 2-3 minutes to be completed. Replace this cell with your code to try different reservoir sizes. In each case, print your estimate for the relative and absolute frequency of the words in the entire dataset.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_frequencies_for_reservoir(filename, reservoir_size, max_words=-1, report_every=10000, top_n=5):\n",
        "        # Perform reservoir sampling\n",
        "        words_read, reservoir = reservoir_sampling(filename, [POS_ADJECTIVE], reservoir_size, max_words=max_words, report_every=report_every)\n",
        "\n",
        "        # Compute frequencies in the reservoir\n",
        "        freq = {}\n",
        "        for item in reservoir:\n",
        "            freq[item] = reservoir.count(item)\n",
        "\n",
        "        # Compute estimates for the dataset\n",
        "        estimates = [\n",
        "            (word, count, count * len(reservoir) / reservoir_size)\n",
        "            for word, count in freq.items()\n",
        "        ]\n",
        "\n",
        "        # Sort by estimated frequency\n",
        "        estimates.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Reservoir size: {reservoir_size}\")\n",
        "        print(f\"Top {top_n} words and their frequency estimates:\")\n",
        "        for word, count_in_reservoir, estimated_absolute_frequency in estimates[:top_n]:\n",
        "            estimated_relative_frequency = (estimated_absolute_frequency / len(reservoir)) * 100\n",
        "            print(f\"{word}: Count in reservoir = {count_in_reservoir}, Estimated absolute frequency = {estimated_absolute_frequency:.2f}, Estimated relative frequency = {estimated_relative_frequency:.2f}%\")"
      ],
      "metadata": {
        "id": "orlwpg0YyVzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reservoir_sizes = [50, 100, 500, 1000, 5000]\n",
        "\n",
        "# Run the function to compute frequency estimates\n",
        "for reservoir_size in reservoir_sizes:\n",
        "  estimate_frequencies_for_reservoir(INPUT_FILE, reservoir_size, max_words=30000)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkaQiagjrDCs",
        "outputId": "7fce6854-c735-4f62-ca7e-b18246952b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Reservoir size: 50\n",
            "Top 5 words and their frequency estimates:\n",
            "little: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 6.00%\n",
            "sure: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 6.00%\n",
            "good: Count in reservoir = 2, Estimated absolute frequency = 2.00, Estimated relative frequency = 4.00%\n",
            "tough: Count in reservoir = 2, Estimated absolute frequency = 2.00, Estimated relative frequency = 4.00%\n",
            "first: Count in reservoir = 2, Estimated absolute frequency = 2.00, Estimated relative frequency = 4.00%\n",
            "\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Reservoir size: 100\n",
            "Top 5 words and their frequency estimates:\n",
            "good: Count in reservoir = 5, Estimated absolute frequency = 5.00, Estimated relative frequency = 5.00%\n",
            "big: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 3.00%\n",
            "little: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 3.00%\n",
            "weird: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 3.00%\n",
            "sure: Count in reservoir = 3, Estimated absolute frequency = 3.00, Estimated relative frequency = 3.00%\n",
            "\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Reservoir size: 500\n",
            "Top 5 words and their frequency estimates:\n",
            "good: Count in reservoir = 18, Estimated absolute frequency = 18.00, Estimated relative frequency = 3.60%\n",
            "sure: Count in reservoir = 14, Estimated absolute frequency = 14.00, Estimated relative frequency = 2.80%\n",
            "big: Count in reservoir = 13, Estimated absolute frequency = 13.00, Estimated relative frequency = 2.60%\n",
            "dead: Count in reservoir = 13, Estimated absolute frequency = 13.00, Estimated relative frequency = 2.60%\n",
            "right: Count in reservoir = 12, Estimated absolute frequency = 12.00, Estimated relative frequency = 2.40%\n",
            "\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Reservoir size: 1000\n",
            "Top 5 words and their frequency estimates:\n",
            "good: Count in reservoir = 38, Estimated absolute frequency = 38.00, Estimated relative frequency = 3.80%\n",
            "dead: Count in reservoir = 26, Estimated absolute frequency = 26.00, Estimated relative frequency = 2.60%\n",
            "sure: Count in reservoir = 22, Estimated absolute frequency = 22.00, Estimated relative frequency = 2.20%\n",
            "other: Count in reservoir = 22, Estimated absolute frequency = 22.00, Estimated relative frequency = 2.20%\n",
            "little: Count in reservoir = 22, Estimated absolute frequency = 22.00, Estimated relative frequency = 2.20%\n",
            "\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Reservoir size: 5000\n",
            "Top 5 words and their frequency estimates:\n",
            "good: Count in reservoir = 188, Estimated absolute frequency = 188.00, Estimated relative frequency = 3.76%\n",
            "little: Count in reservoir = 121, Estimated absolute frequency = 121.00, Estimated relative frequency = 2.42%\n",
            "right: Count in reservoir = 98, Estimated absolute frequency = 98.00, Estimated relative frequency = 1.96%\n",
            "other: Count in reservoir = 91, Estimated absolute frequency = 91.00, Estimated relative frequency = 1.82%\n",
            "much: Count in reservoir = 90, Estimated absolute frequency = 90.00, Estimated relative frequency = 1.80%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdPASFZlD_pQ"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary indicating what reservoir size you would recommend to use, and your overall conclusions.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see there is a big difference of top-5 between reservoir_size=50 and reservoir_size=100. Between reservoir_size=100 and reservoir_size=500, we can see one match 'good' but there is not enough matches to say reservoir_size=100 es the best option.\n",
        "\n",
        "Between reservoir_size=500 and reservoir_size=1000 we can see four matches 'good', 'right', 'big' and 'sure'. So, reservoir_size=500can be a good candidate.\n",
        "\n",
        "Between reservoir_size=1000 and reservoir_size=5000 we just see two matches 'good' and 'right'. There is not a lof of matchese to take into account.\n",
        "\n",
        "To conclude, the best reservoir size is 500 due to amount matches between reservoir_size=500 and reservoir_size=1000."
      ],
      "metadata": {
        "id": "bkfSLojECH92"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM9His3wD_pQ"
      },
      "source": [
        "# 2. Determine approximately the distinct number of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuZ-itSBD_pQ"
      },
      "outputs": [],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "def count_trailing_zeroes(number):\n",
        "    count = 0\n",
        "    while number & 1 == 0:\n",
        "        count += 1\n",
        "        number = number >> 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmoyX00iD_pR"
      },
      "outputs": [],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "def random_hash_function():\n",
        "    # We use a cryptographically safe generator for the salt of our hash function\n",
        "    salt = secrets.token_bytes(32)\n",
        "    return lambda string: hash(string + str(salt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTcFXUbOD_pR"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code to perform the requested number of passes.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
        "              for line in file:\n",
        "                  for word in line.split():'''"
      ],
      "metadata": {
        "id": "5fRbPFENJWwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "91ddc618-5002-4a5f-b612-f4fde72190fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'with gzip.open(INPUT_FILE, \"rt\", encoding=\\'utf8\\') as file:\\n              for line in file:\\n                  for word in line.split():'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_estimates(POS, filename=INPUT_FILE, max_words=30000, number_of_passes=5, report_every=10000):\n",
        "  estimates = []\n",
        "  for i in range(number_of_passes):\n",
        "      # Generate a new random hash function for this pass\n",
        "          hash_function = random_hash_function()\n",
        "\n",
        "          # Initialize maximum trailing zeroes seen\n",
        "          max_trailing_zeroes = 0\n",
        "\n",
        "          # Read the file and process each word\n",
        "          for word in read_by_parts_of_speech(filename, POS, max_words=max_words, report_every=report_every):\n",
        "              # Compute the hash value and count trailing zeroes\n",
        "              hash_value = hash_function(word)\n",
        "              trailing_zeroes = count_trailing_zeroes(abs(hash_value))\n",
        "              max_trailing_zeroes = max(max_trailing_zeroes, trailing_zeroes)\n",
        "\n",
        "          # Estimate based on the maximum trailing zeroes\n",
        "          estimate = 2 ** max_trailing_zeroes\n",
        "          estimates.append(estimate)\n",
        "          print(f\"Estimate on pass {i + 1}: {estimate} distinct words\")\n",
        "  return estimates"
      ],
      "metadata": {
        "id": "CMFr0OgjHTqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimates=calculate_estimates(POS=[POS_ADJECTIVE, POS_NOUN, POS_VERB])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtGgwowgwiV3",
        "outputId": "cff60e16-8e25-48a2-957c-8717f6d48864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Estimate on pass 1: 8192 distinct words\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Estimate on pass 2: 4096 distinct words\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Estimate on pass 3: 2048 distinct words\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Estimate on pass 4: 2048 distinct words\n",
            "- Read 10000/30000 words so far\n",
            "- Read 20000/30000 words so far\n",
            "- Read 30000/30000 words so far\n",
            "Estimate on pass 5: 2048 distinct words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjKTLHRdD_pR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86634a9f-3942-44e4-8b1e-205f7440cf81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Average of estimates: 3686.4\n",
            "* Median  of estimates: 2048.0\n"
          ]
        }
      ],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "print(\"* Average of estimates: %.1f\" % statistics.mean(estimates))\n",
        "print(\"* Median  of estimates: %.1f\" % statistics.median(estimates))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nel8o9beD_pR"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Compute the median of average estimates in 3 separate runs of your algorithm; each run should do 10 passes over the file. Repeat this for nouns (POS_NOUN), adjectives (POS_ADJECTIVE), and verbs (POS_VERB). Replace this cell with the results you obtained in each pass, and whether the average or the median seem more appropriate for this probabilistic counting.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "POST=[POS_ADJECTIVE, POS_NOUN, POS_VERB]\n",
        "for pos in POST:\n",
        "  start_time = time.time()\n",
        "  print(f\"\\nPOS = {pos}:\")\n",
        "  for run in range(3):\n",
        "      print(f\"\\nRun {run + 1} :\")\n",
        "      estimates_passes = calculate_estimates(POS=[pos], filename=INPUT_FILE, number_of_passes=10, max_words=10000)\n",
        "      print(f\"Median of estimates: {statistics.median(estimates_passes)}\")\n",
        "      print(f\"Average of estimates: {statistics.mean(estimates_passes)}\")\n",
        "  elapsed_time = time.time() - start_time\n",
        "  print(f\"\\nTotal time to POS = {pos}: {elapsed_time:.2f} seconds\\n\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDNxj-bMw4bQ",
        "outputId": "8de144a6-02a9-4e13-a45c-f37bac6abff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS = JJ:\n",
            "\n",
            "Run 1 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 16384 distinct words\n",
            "Median of estimates: 6144.0\n",
            "Average of estimates: 7705.6\n",
            "\n",
            "Run 2 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 2048 distinct words\n",
            "Median of estimates: 2048.0\n",
            "Average of estimates: 6246.4\n",
            "\n",
            "Run 3 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 32768 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 65536 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 2048 distinct words\n",
            "Median of estimates: 3072.0\n",
            "Average of estimates: 12697.6\n",
            "\n",
            "Total time to POS = JJ: 411.15 seconds\n",
            "\n",
            "\n",
            "\n",
            "POS = NN:\n",
            "\n",
            "Run 1 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 65536 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 32768 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 32768 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 2048 distinct words\n",
            "Median of estimates: 2048.0\n",
            "Average of estimates: 14848\n",
            "\n",
            "Run 2 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 32768 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 8192 distinct words\n",
            "Median of estimates: 2048.0\n",
            "Average of estimates: 6451.2\n",
            "\n",
            "Run 3 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 65536 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 65536 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 32768 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 1024 distinct words\n",
            "Median of estimates: 4096.0\n",
            "Average of estimates: 18585.6\n",
            "\n",
            "Total time to POS = NN: 173.19 seconds\n",
            "\n",
            "\n",
            "\n",
            "POS = VB:\n",
            "\n",
            "Run 1 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 16384 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 4096 distinct words\n",
            "Median of estimates: 512.0\n",
            "Average of estimates: 4172.8\n",
            "\n",
            "Run 2 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 8192 distinct words\n",
            "Median of estimates: 1024.0\n",
            "Average of estimates: 2432\n",
            "\n",
            "Run 3 :\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 1: 2048 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 2: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 3: 1024 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 4: 8192 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 5: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 6: 4096 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 7: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 8: 256 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 9: 512 distinct words\n",
            "- Read 10000/10000 words so far\n",
            "Estimate on pass 10: 1024 distinct words\n",
            "Median of estimates: 1024.0\n",
            "Average of estimates: 2278.4\n",
            "\n",
            "Total time to POS = VB: 314.20 seconds\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decrease the max_words because a max_words higher than 10000 waste more than 5 minuts."
      ],
      "metadata": {
        "id": "Pcviui0YXvh7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwShuHErD_pS"
      },
      "source": [
        "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}